from openai import AsyncOpenAI
from typing import Dict, Any
import json
import asyncio

from app.config import settings

class OpenAIService:
    def __init__(self):
        # GeÃ§ici olarak mock response kullan - OpenAI API client sorunu nedeniyle
        print("Using mock responses for OpenAI API")
        self.client = None
        # if settings.openai_api_key:
        #     self.client = AsyncOpenAI(api_key=settings.openai_api_key)
        # else:
        #     print("Warning: OpenAI API key not found. Using mock responses.")
        #     self.client = None
    
    async def get_analysis_insights(self, prompt: str) -> str:
        """Analiz iÃ§in OpenAI'den insights al"""
        if not self.client:
            return self._get_mock_analysis_response()
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Sen bir iÅŸ analisti ve veri uzmanÄ±sÄ±n. TÃ¼rkÃ§e cevap ver."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"OpenAI API error: {e}")
            return self._get_mock_analysis_response()
    
    async def ask_question(self, file_data: Dict[str, Any], question: str) -> str:
        """Dosya hakkÄ±nda soru sor"""
        if not self.client:
            return self._get_mock_question_response(question, file_data)
        
        try:
            # Dosya verisini Ã¶zet olarak hazÄ±rla
            data_summary = self._prepare_data_summary(file_data)
            
            prompt = f"""
            AÅŸaÄŸÄ±daki veri analizi sonuÃ§larÄ±na dayanarak kullanÄ±cÄ±nÄ±n sorusunu cevapla:
            
            Veri Ã–zeti:
            {data_summary}
            
            KullanÄ±cÄ±nÄ±n Sorusu: {question}
            
            LÃ¼tfen veri analiz sonuÃ§larÄ±na dayanarak detaylÄ± ve faydalÄ± bir cevap ver.
            """
            
            response = await self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Sen bir veri analisti ve business intelligence uzmanÄ±sÄ±n. TÃ¼rkÃ§e cevap ver."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"OpenAI API error: {e}")
            return f"Sorunuzla ilgili analiz yapÄ±ldÄ± ancak detaylÄ± cevap ÅŸu anda verilemedi. Temel veri incelemesi tamamlandÄ±."
    
    def _prepare_data_summary(self, file_data: Dict[str, Any]) -> str:
        """Dosya verisini Ã¶zet olarak hazÄ±rla"""
        summary = f"Dosya TÃ¼rÃ¼: {file_data.get('file_type', 'Bilinmiyor')}\n"
        
        if 'data_overview' in file_data:
            summary += "Veri Genel BakÄ±ÅŸ:\n"
            for key, value in file_data['data_overview'].items():
                if isinstance(value, dict):
                    summary += f"- {key}: {str(value)[:200]}...\n"
        
        return summary[:1000]  # OpenAI token limitini aÅŸmamak iÃ§in kÄ±salt
    
    def _get_mock_analysis_response(self) -> str:
        """OpenAI API olmadÄ±ÄŸÄ±nda mock response"""
        return """
        Veri analizi tamamlandÄ±. Genel bulgular:
        
        â€¢ Veri kalitesi genel olarak iyi durumda
        â€¢ SayÄ±sal deÄŸerlerde tutarlÄ±lÄ±k gÃ¶zlendi
        â€¢ Potansiyel iyileÅŸtirme alanlarÄ± tespit edildi
        â€¢ DetaylÄ± inceleme iÃ§in ek analizler Ã¶nerilir
        
        Bu analiz temel istatistiksel yÃ¶ntemler kullanÄ±larak gerÃ§ekleÅŸtirildi.
        """
    
    def _get_mock_question_response(self, question: str, file_data: Dict[str, Any]) -> str:
        """GerÃ§ek veriye dayalÄ± soru cevaplama"""
        question_lower = question.lower()
        
        # Dosya verilerini analiz et
        stats_summary = self._analyze_file_data_for_questions(file_data)
        
        # Ana bulgular sorularÄ±
        if any(word in question_lower for word in ['ana bulgular', 'ana bulgu', 'temel bulgular', 'sonuÃ§lar']):
            return f"""
            ğŸ“Š **Ana Bulgular** (GerÃ§ek Veri Analizi):
            
            ï¿½ **Dosya TÃ¼rÃ¼**: {file_data.get('file_type', 'Bilinmiyor').upper()}
            ğŸ“Š **Veri Boyutu**: {stats_summary.get('total_rows', 0):,} satÄ±r
            ï¿½ **SayÄ±sal SÃ¼tunlar**: {stats_summary.get('numeric_columns', 0)} adet
            
            ğŸ¯ **Temel Ä°statistikler**:
            {stats_summary.get('main_stats', 'HesaplanÄ±yor...')}
            
            âš¡ **Veri Kalitesi**: {stats_summary.get('data_quality', 'Ä°yi')}
            
            Detaylar iÃ§in ilgili sekmeleri inceleyebilirsiniz.
            """
        
        # Trend sorularÄ±
        elif any(word in question_lower for word in ['trend', 'yÃ¶n', 'artÄ±ÅŸ', 'azalÄ±ÅŸ', 'deÄŸiÅŸim']):
            return f"""
            ï¿½ **Trend Analizi** (GerÃ§ek Veriler):
            
            {stats_summary.get('trend_info', 'ğŸ“Š Trend analizi yapÄ±lÄ±yor...')}
            
            **ğŸ’¡ Ã–neri**: Bu trendlerin nedenlerini araÅŸtÄ±rmanÄ±zÄ± ve gelecek projeksiyonlarÄ± yapmanÄ±zÄ± Ã¶neriyorum.
            """
        
        # Aksiyon/eylem sorularÄ±  
        elif any(word in question_lower for word in ['aksiyon', 'eylem', 'yapmalÄ±', 'Ã¶ncelik', 'adÄ±m']):
            return f"""
            âœ… **Ã–nerilen Eylemler** (Veri Analizine DayalÄ±):
            
            {stats_summary.get('recommendations', 'â€¢ Veri analizi sonuÃ§larÄ±nÄ± inceleyin')}
            
            Bu Ã¶neriler, mevcut veri analizinize dayanmaktadÄ±r.
            """
            
        # KPI sorularÄ±
        elif any(word in question_lower for word in ['kpi', 'metrik', 'deÄŸer', 'Ã¶lÃ§Ã¼m']):
            return f"""
            ğŸ“Š **KPI Analizi** (GerÃ§ek Veriler):
            
            {stats_summary.get('kpi_info', 'ğŸ”¢ KPI hesaplamalarÄ± yapÄ±lÄ±yor...')}
            
            Bu deÄŸerler, yÃ¼klediÄŸiniz dosyadaki gerÃ§ek verilerden hesaplanmÄ±ÅŸtÄ±r.
            """
            
        # Maksimum/minimum deÄŸer sorularÄ±
        elif any(word in question_lower for word in ['maksimum', 'minimum', 'en yÃ¼ksek', 'en dÃ¼ÅŸÃ¼k', 'max', 'min']):
            return f"""
            ï¿½ **Ekstrem DeÄŸerler**:
            
            {stats_summary.get('extremes', 'ï¿½ Ekstrem deÄŸerler hesaplanÄ±yor...')}
            """
        
        # Genel sorular
        else:
            return f"""
            ï¿½ **Veri Analizi Ã–zeti**:
            
            "{question}" sorunuzla ilgili analiz sonuÃ§larÄ±:
            
            ï¿½ **Dosya**: {file_data.get('file_type', 'Bilinmiyor')} formatÄ±nda
            ğŸ“ˆ **Veri Boyutu**: {stats_summary.get('total_rows', 0):,} satÄ±r
            ğŸ”¢ **Analizler**: {stats_summary.get('analysis_count', 'Ã‡eÅŸitli')} analiz yapÄ±ldÄ±
            
            Daha detaylÄ± bilgi iÃ§in spesifik sorular sorabilirsiniz:
            â€¢ "Ana bulgular neler?"
            â€¢ "En yÃ¼ksek deÄŸerler nerede?"
            â€¢ "Hangi trendler var?"
            """
    
    def _analyze_file_data_for_questions(self, file_data: Dict[str, Any]) -> Dict[str, Any]:
        """Dosya verilerini soru cevaplama iÃ§in analiz et"""
        summary = {
            'total_rows': 0,
            'numeric_columns': 0,
            'main_stats': '',
            'data_quality': 'Ä°yi',
            'trend_info': '',
            'recommendations': '',
            'kpi_info': '',
            'extremes': '',
            'analysis_count': 0,
            'categorical_info': '',
            'time_period': '',
            'data_insights': ''
        }
        
        try:
            if file_data.get('file_type') in ['csv', 'excel']:
                # CSV/Excel verilerini analiz et
                if 'data' in file_data and file_data['data']:
                    import pandas as pd
                    df = pd.DataFrame(file_data['data'])
                    
                    summary['total_rows'] = len(df)
                    
                    # Numerik sÃ¼tunlarÄ± tespit et (daha geliÅŸmiÅŸ)
                    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                    
                    # String sÃ¼tunlarÄ± sayÄ±ya Ã§evirmeyi dene
                    for col in df.columns:
                        if col not in numeric_cols and df[col].dtype == 'object':
                            try:
                                # VirgÃ¼lleri nokta yap ve sayÄ±ya Ã§evir
                                converted = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')
                                if not converted.isna().all():
                                    df[col] = converted
                                    numeric_cols.append(col)
                            except:
                                continue
                    
                    summary['numeric_columns'] = len(numeric_cols)
                    
                    # Zaman bilgisi tespit et
                    date_cols = []
                    for col in df.columns:
                        if any(word in col.lower() for word in ['tarih', 'date', 'time', 'zaman']):
                            try:
                                df[col] = pd.to_datetime(df[col], errors='coerce')
                                if not df[col].isna().all():
                                    date_cols.append(col)
                                    min_date = df[col].min()
                                    max_date = df[col].max()
                                    summary['time_period'] = f"{min_date.strftime('%Y-%m-%d')} - {max_date.strftime('%Y-%m-%d')}"
                            except:
                                continue
                    
                    if len(numeric_cols) > 0:
                        # Ana istatistikler - daha detaylÄ±
                        stats_text = []
                        for col in numeric_cols[:3]:  # Ä°lk 3 sÃ¼tun
                            clean_data = df[col].dropna()
                            if len(clean_data) > 0:
                                mean_val = clean_data.mean()
                                if mean_val > 1000000:
                                    stats_text.append(f"â€¢ {col.replace('_', ' ').title()}: Ort. {mean_val/1000000:.1f}M")
                                elif mean_val > 1000:
                                    stats_text.append(f"â€¢ {col.replace('_', ' ').title()}: Ort. {mean_val/1000:.1f}K") 
                                else:
                                    stats_text.append(f"â€¢ {col.replace('_', ' ').title()}: Ort. {mean_val:.2f}")
                        summary['main_stats'] = '\n            '.join(stats_text)
                        
                        # GeliÅŸmiÅŸ trend bilgisi
                        trend_texts = []
                        for col in numeric_cols[:2]:  # Ä°lk 2 sÃ¼tun iÃ§in trend
                            clean_data = df[col].dropna()
                            if len(clean_data) > 1:
                                std_val = clean_data.std()
                                mean_val = clean_data.mean()
                                cv = (std_val / mean_val * 100) if mean_val != 0 else 0
                                
                                # Zaman serisi trend analizi
                                if date_cols and len(clean_data) > 5:
                                    df_sorted = df.sort_values(date_cols[0])
                                    values = df_sorted[col].dropna()
                                    first_quarter = values.head(len(values)//4).mean()
                                    last_quarter = values.tail(len(values)//4).mean()
                                    
                                    if last_quarter > first_quarter * 1.1:
                                        trend_texts.append(f"ğŸ“ˆ **{col.replace('_', ' ').title()}**: ArtÄ±ÅŸ trendi (%{((last_quarter-first_quarter)/first_quarter*100):.1f})")
                                    elif last_quarter < first_quarter * 0.9:
                                        trend_texts.append(f"ğŸ“‰ **{col.replace('_', ' ').title()}**: AzalÄ±ÅŸ trendi (%{((first_quarter-last_quarter)/first_quarter*100):.1f})")
                                    else:
                                        trend_texts.append(f"ğŸ“Š **{col.replace('_', ' ').title()}**: Stabil trend")
                                else:
                                    if cv > 50:
                                        trend_texts.append(f"ğŸ“Š **{col.replace('_', ' ').title()}**: YÃ¼ksek deÄŸiÅŸkenlik (%{cv:.1f})")
                                    elif cv < 10:
                                        trend_texts.append(f"ğŸ“ˆ **{col.replace('_', ' ').title()}**: Stabil deÄŸerler (%{cv:.1f})")
                                    else:
                                        trend_texts.append(f"ğŸ“Š **{col.replace('_', ' ').title()}**: Orta seviye deÄŸiÅŸkenlik (%{cv:.1f})")
                        
                        summary['trend_info'] = '\n            '.join(trend_texts)
                        
                        # KPI bilgisi - daha anlamlÄ±
                        kpi_texts = []
                        for col in numeric_cols[:3]:
                            clean_data = df[col].dropna()
                            if len(clean_data) > 0:
                                total_val = clean_data.sum()
                                count_val = len(clean_data)
                                unit = "MWh" if 'mwh' in col.lower() else ""
                                kpi_texts.append(f"ğŸ”¢ **{col.replace('_', ' ').title()}**: Toplam {total_val:,.0f} {unit}, {count_val} kayÄ±t")
                        summary['kpi_info'] = '\n            '.join(kpi_texts)
                        
                        # Ekstrem deÄŸerler
                        extreme_texts = []
                        for col in numeric_cols[:2]:
                            clean_data = df[col].dropna()
                            if len(clean_data) > 0:
                                max_val = clean_data.max()
                                min_val = clean_data.min()
                                extreme_texts.append(f"ğŸ“Š **{col.replace('_', ' ').title()}**: En YÃ¼ksek {max_val:,.2f}, En DÃ¼ÅŸÃ¼k {min_val:,.2f}")
                        summary['extremes'] = '\n            '.join(extreme_texts)
                        
                        summary['analysis_count'] = len(numeric_cols)
                    
                    # Kategorik veri analizi
                    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
                    categorical_info = []
                    for col in categorical_cols[:2]:  # Ä°lk 2 kategorik sÃ¼tun
                        if col not in date_cols:  # Tarih sÃ¼tunlarÄ± hariÃ§
                            unique_count = df[col].nunique()
                            most_common = df[col].mode().iloc[0] if len(df[col].mode()) > 0 else "N/A"
                            categorical_info.append(f"ğŸ“‹ **{col.replace('_', ' ').title()}**: {unique_count} farklÄ± deÄŸer, En yaygÄ±n: {most_common}")
                    summary['categorical_info'] = '\n            '.join(categorical_info)
                    
                    # Ã–neriler - daha akÄ±llÄ±
                    recommendations = []
                    missing_count = df.isnull().sum().sum()
                    if missing_count > 0:
                        recommendations.append(f"ğŸ”´ **YÃ¼ksek Ã–ncelik**: {missing_count} eksik veri tespit edildi, tamamlanmasÄ± Ã¶nerilir")
                    
                    # AykÄ±rÄ± deÄŸer kontrolÃ¼
                    for col in numeric_cols[:2]:
                        clean_data = df[col].dropna()
                        if len(clean_data) > 10:
                            q1 = clean_data.quantile(0.25)
                            q3 = clean_data.quantile(0.75)
                            iqr = q3 - q1
                            outliers = clean_data[(clean_data < (q1 - 1.5 * iqr)) | (clean_data > (q3 + 1.5 * iqr))]
                            if len(outliers) > len(clean_data) * 0.05:  # %5'ten fazla aykÄ±rÄ± deÄŸer
                                recommendations.append(f"ğŸŸ¡ **Orta Ã–ncelik**: {col.replace('_', ' ').title()} sÃ¼tununda {len(outliers)} aykÄ±rÄ± deÄŸer tespit edildi")
                                break
                    
                    if len(recommendations) == 0:
                        recommendations.append("ğŸŸ¢ **Veri Kalitesi Ä°yi**: BÃ¼yÃ¼k bir veri kalitesi sorunu tespit edilmedi")
                    
                    recommendations.append("ğŸ’¡ **Ã–neri**: DÃ¼zenli veri analizi ve raporlama sistemi kurun")
                    summary['recommendations'] = '\n            '.join(recommendations)
                    
                    # Veri kalitesi deÄŸerlendirmesi
                    missing_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))
                    if missing_ratio > 0.1:
                        summary['data_quality'] = f'Ä°yileÅŸtirilebilir (%{missing_ratio*100:.1f} eksik veri)'
                    elif missing_ratio > 0.05:
                        summary['data_quality'] = f'Ä°yi (%{missing_ratio*100:.1f} eksik veri)'
                    else:
                        summary['data_quality'] = 'MÃ¼kemmel (minimal eksik veri)'
                    
                    # Genel veri insights
                    insights = []
                    if len(df) > 1000:
                        insights.append("ğŸ“Š BÃ¼yÃ¼k veri seti - istatistiksel analizler gÃ¼venilir")
                    if len(numeric_cols) > 3:
                        insights.append("ğŸ”¢ Ã‡ok sayÄ±da numerik sÃ¼tun - kapsamlÄ± metrik analizi mÃ¼mkÃ¼n")
                    if date_cols:
                        insights.append("ğŸ“… Zaman serisi verisi - trend analizi yapÄ±labilir")
                    if len(categorical_cols) > 0:
                        insights.append("ğŸ“‹ Kategorik veriler - segmentasyon analizi mÃ¼mkÃ¼n")
                    
                    summary['data_insights'] = ' | '.join(insights)
        
        except Exception as e:
            print(f"Question analysis error: {str(e)}")
            summary['main_stats'] = f'Analiz hatasÄ±: {str(e)}'
            
        return summary